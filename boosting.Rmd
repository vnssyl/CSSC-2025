---
title: "Data Cleaning"
date: "2025-04-26"
output: pdf_document
---

```{r setup, warning=FALSE, message=FALSE}
# -------------------------------
# INSTALL & LOAD PACKAGES
# -------------------------------
library(data.table)
library(readxl)
library(fst)
library(corrplot)
library(survival)
library(caret)
library(gbm)
library(survivalROC)
library(survcomp)
library(purr)

library(survAUC) #For calculating C index
```

```{r data-cleaning, warning=FALSE, message=FALSE}
# -------------------------------
# STEP 1â€“4: LOAD AND SELECT DATA
# -------------------------------
data <- readxl::read_excel("../synthetic_data_stats_competition_2025_final.xlsx")
data <- as.data.table(data)

# Save & reload as fst for speed
write_fst(data, "../data.fst")
data <- read_fst("../data.fst", as.data.table = TRUE)

# ------------------------
# STEP 2: Calculate missing %
# ------------------------
missing_percent <- data[, lapply(.SD, function(x) sum(is.na(x)) / .N)]

# ------------------------
# STEP 3: Define outcome & important labs
# ------------------------
outcome_vars <- c(
  "outcome_afib_aflutter_new_post",
  "time_to_outcome_afib_aflutter_new_post",
  "outcome_all_cause_death",
  "time_to_outcome_all_cause_death",
  "follow_up_duration"
)

drop_vars <- names(missing_percent)[
  (unlist(missing_percent) >= 0.3) & 
  !(names(missing_percent) %in% outcome_vars)
]

cat("Variables dropped:", drop_vars, "\n")

# ------------------------
# STEP 4: Keep final vars
# ------------------------
final_vars <- c("patient_id", outcome_vars, setdiff(names(data), drop_vars))
data <- data[, ..final_vars]

# ------------------------
# STEP 5: Impute missing values (only columns that have missing)
# ------------------------
numeric_cols <- names(data)[sapply(data, is.numeric)]
cor_matrix <- cor(data[, ..numeric_cols], use = "pairwise.complete.obs")

for (col in names(data)) {
  if (!any(is.na(data[[col]]))) next  # skip if no missing in this column
  
  if (col %in% numeric_cols) {
    other_cols <- setdiff(numeric_cols, col)
    cor_values <- abs(cor_matrix[col, other_cols])
    max_cor <- max(cor_values, na.rm = TRUE)
    best_predictor <- other_cols[which.max(cor_values)]
    
    if (max_cor > 0.7) {
      # create model_data with distinct names
      model_data <- data[!is.na(get(col)) & !is.na(get(best_predictor)),
                         .(target = get(col), pred_val = get(best_predictor))]
      if (nrow(model_data) > 10) {
        model <- lm(target ~ pred_val, data = model_data)
        missing_idx <- which(is.na(data[[col]]) & !is.na(data[[best_predictor]]))
        data[missing_idx, (col) := predict(model, 
                                  newdata = data.table(pred_val = data[[best_predictor]][missing_idx]))]
      }
    } 
    
    # If low correlation or not enough data, impute with mean
    if (max_cor <= 0.7 || nrow(model_data) <= 10) {
      mean_value <- mean(data[[col]], na.rm = TRUE)
      data[is.na(get(col)), (col) := mean_value]
    }
    
  } else {
    # Categorical columns, impute with mode
    mode_value <- names(sort(table(data[[col]]), decreasing = TRUE))[1]
    data[is.na(get(col)), (col) := mode_value]
  }
}

# ------------------------
# STEP 6: Correct variable types
# ------------------------
for (col in names(data)) {
  if (is.character(data[[col]])) next
  if (is.numeric(data[[col]])) {
    uniq_vals <- unique(na.omit(data[[col]]))
    if (length(uniq_vals) == 2) {
      data[, (col) := factor(data[[col]])]
    } else {
      data[, (col) := as.numeric(data[[col]])]
    }
  }
}

# ------------------------
# STEP 7: Define survival time and event
# ------------------------
data[, event_afib := as.integer(outcome_afib_aflutter_new_post == 1)]
data[, time_afib := fifelse(
  outcome_afib_aflutter_new_post == 1,
  time_to_outcome_afib_aflutter_new_post,
  fifelse(
    outcome_all_cause_death == 1,
    time_to_outcome_all_cause_death,
    follow_up_duration
  )
)]
data <- data[!is.na(time_afib)]

# ------------------------
# STEP 8: Train-Test Split (30% training, 70% testing)
# ------------------------
set.seed(123)
train_indices <- sample(seq_len(nrow(data)), size = 0.3 * nrow(data))
train_data <- data[train_indices] # This one to feed into model
test_data <- data[-train_indices] # Use this one for AUC, C-index, etc


# ------------------------
# STEP 9: Save survival-ready data
# ------------------------
write_fst(data, "../data_survival_ready_final.fst")
```
```{r}
# Tuning
param_grid <- expand.grid(
  n.trees = c(1000, 2000, 3000),
  interaction.depth = c(1, 3, 5),
  shrinkage = c(0.01, 0.05),
  bag.fraction = c(0.6, 0.8)
)

set.seed(123)
folds <- sample(1:5, nrow(boost_data), replace = TRUE)


# Function to evaluate one combo
evaluate_combo <- function(params) {
  cindexes <- numeric(5)

  for (k in 1:5) {
    train_idx <- which(folds != k)
    test_idx <- which(folds == k)

    train_data <- boost_data[train_idx, ]
    test_data <- boost_data[test_idx, ]

    model <- gbm(
      formula = Surv(time_afib, event_afib) ~ .,
      data = train_data,
      distribution = "coxph",
      n.trees = params$n.trees,
      interaction.depth = params$interaction.depth,
      shrinkage = params$shrinkage,
      bag.fraction = params$bag.fraction,
      train.fraction = 1.0,  # use full training fold
      verbose = FALSE
    )

    pred <- predict(model, newdata = test_data, n.trees = params$n.trees, type = "link")

    cindexes[k] <- concordance.index(
      x = pred,
      surv.time = test_data$time_afib,
      surv.event = test_data$event_afib,
      method = "noether"
    )$c.index
  }

  mean(cindexes)
}

# Run the tuning
param_grid$cindex <- pmap_dbl(param_grid, evaluate_combo)

best_params <- param_grid %>%
  arrange(desc(cindex)) %>%
  slice(1)

print(best_params)
```

```{r}
# ------------------------
# STEP 10: Survival Boosting with GBM
# ------------------------
predictor_vars <- setdiff(
  names(data),
  c("patient_id", "event_afib", "time_afib", outcome_vars)
)

# Prepare data for training GBM
boost_data <- as.data.frame(train_data[, c("time_afib", "event_afib", predictor_vars), with = FALSE])

# Fit GBM Cox model
set.seed(123)
gbm_fit <- gbm(
  formula = Surv(time_afib, event_afib) ~ .,
  data = boost_data,
  distribution = "coxph",
  n.trees = 3000,
  interaction.depth = 3,
  shrinkage = 0.01,
  bag.fraction = 0.7,
  train.fraction = 0.8,
  cv.folds = 5,
  n.minobsinnode = 10,
  verbose = FALSE
)

# Select best iteration using cross-validation
best_iter <- gbm.perf(gbm_fit, method = "cv")

# Variable importance plot
importance <- summary(gbm_fit, n.trees = best_iter, plotit = FALSE)
barplot(
  importance[1:20, "rel.inf"], 
  names.arg = importance[1:20, "var"],
  las = 2,
  main = "Top 20 Variables (GBM Boosting)"
)
```

```{r}
# ------------------------
# STEP 12: Variable Importance Table (Base R + data.table only)
# ------------------------

# Get importance from GBM
importance <- summary(gbm_fit, n.trees = best_iter, plotit = FALSE)

# Convert to data.table
importance_dt <- as.data.table(importance)
setnames(importance_dt, c("var", "rel.inf"), c("Variable", "RelativeInfluence"))

# Round values for readability
importance_dt[, RelativeInfluence := round(RelativeInfluence, 2)]

# Sort by importance descending
importance_dt <- importance_dt[order(-RelativeInfluence)]

# Print top 20 variables as a normal table
print(importance_dt[1:20])

```


```{r}
# Predict risk scores (linear predictor) on test set
test_boost_data <- as.data.frame(test_data[, predictor_vars, with = FALSE])
predicted_risk <- predict(gbm_fit, newdata = test_boost_data, n.trees = best_iter, type = "link")
test_data[, predicted_risk := predicted_risk]
```


#Performance Scores
```{r}
#4 year
eval_time <- 1480

T_train <- train_data$time_afib
delta_train <- train_data$event_afib

T_test <- test_data$time_afib
delta_test <- test_data$event_afib
lp_test <- test_data$predicted_risk

auc_uno <- AUC.uno(
  Surv.rsp = Surv(T_train, delta_train),    # training survival object
  Surv.rsp.new = Surv(T_test, delta_test),  # testing survival object
  lpnew = lp_test,                          # predicted risk (linear predictor)
  times = eval_time                         # time at which to evaluate
)
str(auc_uno)

#5 year
eval_time <- 1825
T_train <- train_data$time_afib
delta_train <- train_data$event_afib

T_test <- test_data$time_afib
delta_test <- test_data$event_afib
lp_test <- test_data$predicted_risk

auc_uno <- AUC.uno(
  Surv.rsp = Surv(T_train, delta_train),    # training survival object
  Surv.rsp.new = Surv(T_test, delta_test),  # testing survival object
  lpnew = lp_test,                          # predicted risk (linear predictor)
  times = eval_time                         # time at which to evaluate
)
str(auc_uno)

```
